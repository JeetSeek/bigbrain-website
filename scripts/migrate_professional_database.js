#!/usr/bin/env node

/**
 * Professional Database Migration Script
 * Executes the database schema migration and data population for Gas Safe diagnostics
 */

import { createClient } from '@supabase/supabase-js';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Load environment variables
dotenv.config({ path: path.join(__dirname, '../server/.env') });

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_ANON_KEY;

if (!supabaseUrl || !supabaseServiceKey) {
    console.error('‚ùå Missing Supabase configuration in environment variables');
    console.error('Required: SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY (or SUPABASE_ANON_KEY)');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

async function executeSQLFile(filePath, description) {
    
    try {
        const sqlContent = fs.readFileSync(filePath, 'utf8');
        
        // Split SQL content by statements (simple approach)
        const statements = sqlContent
            .split(';')
            .map(stmt => stmt.trim())
            .filter(stmt => stmt.length > 0 && !stmt.startsWith('--'));
        
        
        let successCount = 0;
        let errorCount = 0;
        
        for (let i = 0; i < statements.length; i++) {
            const statement = statements[i];
            if (statement.trim().length === 0) continue;
            
            try {
                const { error } = await supabase.rpc('exec_sql', { sql_query: statement });
                
                if (error) {
                    // Try direct query execution as fallback
                    const { error: directError } = await supabase
                        .from('_temp_migration')
                        .select('*')
                        .limit(0); // This will fail, but we use it to execute raw SQL
                    
                    if (directError && !directError.message.includes('does not exist')) {
                        console.warn(`   ‚ö†Ô∏è  Statement ${i + 1} warning: ${error.message}`);
                        errorCount++;
                    } else {
                        successCount++;
                    }
                } else {
                    successCount++;
                }
            } catch (err) {
                console.warn(`   ‚ö†Ô∏è  Statement ${i + 1} error: ${err.message}`);
                errorCount++;
            }
        }
        
        return { success: successCount, errors: errorCount };
        
    } catch (error) {
        console.error(`   ‚ùå Failed to execute ${description}: ${error.message}`);
        return { success: 0, errors: 1 };
    }
}

async function checkExistingTables() {
    
    try {
        // Check for existing tables
        const { data: tables, error } = await supabase
            .from('information_schema.tables')
            .select('table_name')
            .eq('table_schema', 'public')
            .in('table_name', [
                'diagnostic_fault_codes',
                'boiler_components', 
                'diagnostic_procedures',
                'manufacturers_enhanced',
                'diagnostic_relationships',
                'professional_knowledge_base'
            ]);
        
        if (error) {
            console.log('   ‚ÑπÔ∏è  Could not check existing tables (this is normal for first run)');
            return [];
        }
        
        const existingTables = tables?.map(t => t.table_name) || [];
        
        return existingTables;
        
    } catch (error) {
        console.log('   ‚ÑπÔ∏è  Could not check existing tables (this is normal for first run)');
        return [];
    }
}

async function validateMigration() {
    
    const validationQueries = [
        {
            name: 'diagnostic_fault_codes',
            query: 'SELECT COUNT(*) as count FROM diagnostic_fault_codes'
        },
        {
            name: 'boiler_components',
            query: 'SELECT COUNT(*) as count FROM boiler_components'
        },
        {
            name: 'diagnostic_procedures',
            query: 'SELECT COUNT(*) as count FROM diagnostic_procedures'
        },
        {
            name: 'manufacturers_enhanced',
            query: 'SELECT COUNT(*) as count FROM manufacturers_enhanced'
        }
    ];
    
    const results = {};
    
    for (const validation of validationQueries) {
        try {
            const { data, error } = await supabase.rpc('exec_sql', { 
                sql_query: validation.query 
            });
            
            if (!error && data && data.length > 0) {
                results[validation.name] = data[0].count || 0;
            } else {
                results[validation.name] = 0;
                console.log(`   ‚ö†Ô∏è  ${validation.name}: Could not validate (table may not exist yet)`);
            }
        } catch (err) {
            results[validation.name] = 0;
        }
    }
    
    return results;
}

async function populateProfessionalKnowledgeBase() {
    
    const knowledgeEntries = [
        {
            knowledge_type: 'regulation',
            category: 'gas_safe',
            title: 'Gas Safety (Installation and Use) Regulations - Fault Finding',
            content: `Gas Safe engineers must follow systematic fault finding procedures:
1. Always isolate gas supply before commencing work
2. Check gas tightness after any work on gas connections
3. Complete combustion analysis after any work affecting combustion
4. Issue appropriate certificates for work completed
5. Never leave unsafe situations - make safe or disconnect`,
            gas_safe_regulation_refs: JSON.stringify(['GSIUR Regulation 26', 'GSIUR Regulation 27']),
            professional_level: 'qualified',
            semantic_tags: JSON.stringify(['gas_safe', 'regulations', 'fault_finding', 'safety'])
        },
        {
            knowledge_type: 'procedure',
            category: 'manufacturer_specific',
            title: 'Systematic Boiler Fault Diagnosis Protocol',
            content: `Professional diagnostic sequence for boiler faults:
1. Record ALL fault codes and system status
2. Check basic parameters: gas pressure (20mbar), electrical supply (230V)
3. Follow manufacturer-specific diagnostic procedures
4. Test components systematically, not randomly
5. Verify repairs with full system test and combustion analysis`,
            manufacturer_applicability: JSON.stringify(['all']),
            professional_level: 'qualified',
            semantic_tags: JSON.stringify(['diagnosis', 'systematic', 'fault_codes', 'testing'])
        },
        {
            knowledge_type: 'specification',
            category: 'component',
            title: 'Gas Valve Testing Procedures',
            content: `Professional gas valve testing requirements:
Electrical: Coil resistance 3.2kŒ© ¬±10%, 230V AC operation
Gas tightness: Test at 20mbar with leak detection fluid
Operation: Check opening/closing response <2 seconds
Safety: Always isolate gas supply before electrical testing`,
            component_relevance: JSON.stringify(['gas_valve']),
            professional_level: 'qualified',
            semantic_tags: JSON.stringify(['gas_valve', 'testing', 'electrical', 'gas_tightness'])
        }
    ];
    
    try {
        for (const entry of knowledgeEntries) {
            const { error } = await supabase
                .from('professional_knowledge_base')
                .insert(entry);
            
            if (error) {
            } else {
            }
        }
    } catch (error) {
    }
}

async function main() {
    
    // Check existing structure
    const existingTables = await checkExistingTables();
    
    const migrationsDir = path.join(__dirname, '../database_migrations');
    
    // Execute schema migration
    const schemaResult = await executeSQLFile(
        path.join(migrationsDir, '001_professional_diagnostic_schema.sql'),
        'Professional Diagnostic Schema Creation'
    );
    
    // Execute data migration
    const dataResult = await executeSQLFile(
        path.join(migrationsDir, '002_migrate_existing_data.sql'),
        'Existing Data Migration'
    );
    
    // Populate knowledge base
    await populateProfessionalKnowledgeBase();
    
    // Validate results
    const validation = await validateMigration();
    
    // Summary
    console.log('\nüìà Database Records:');
    Object.entries(validation).forEach(([table, count]) => {
    });
    
    const totalRecords = Object.values(validation).reduce((sum, count) => sum + count, 0);
    
    if (totalRecords > 0) {
        console.log('   1. Update LLM integration to use new diagnostic tables');
    } else {
    }
}

// Execute migration
main().catch(error => {
    console.error('üí• Migration failed:', error);
    process.exit(1);
});
